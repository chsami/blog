<!DOCTYPE html>
<html lang="en">
<head>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-40KNBS6D0Q"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-40KNBS6D0Q');
  </script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>The Red Line: Anthropic Said No to Mass Surveillance. OpenAI Said Yes to the Pentagon. - CHSAMI</title>
  <meta name="description" content="Anthropic refused to let the US military use Claude without ethical safeguards. The government threatened retaliation. Then OpenAI swooped in with a deal. Here's what happened and why it matters.">
  <meta name="author" content="Sami">
  <link rel="canonical" href="https://chsami.com/posts/anthropic-vs-openai-surveillance.html">

  <meta property="og:type" content="article">
  <meta property="og:url" content="https://chsami.com/posts/anthropic-vs-openai-surveillance.html">
  <meta property="og:title" content="The Red Line: Anthropic Said No to Mass Surveillance. OpenAI Said Yes to the Pentagon.">
  <meta property="og:description" content="Anthropic refused to let the US military use Claude without ethical safeguards. The government threatened retaliation. Then OpenAI swooped in with a deal. Here's what happened and why it matters.">
  <meta property="og:image" content="https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=1200&h=630&fit=crop">
  <meta property="og:site_name" content="CHSAMI">
  <meta property="article:published_time" content="2026-02-28">
  <meta property="article:author" content="Sami">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="The Red Line: Anthropic Said No to Mass Surveillance. OpenAI Said Yes to the Pentagon.">
  <meta name="twitter:description" content="Anthropic refused to let the US military use Claude without ethical safeguards. The government threatened retaliation. Then OpenAI swooped in with a deal. Here's what happened and why it matters.">
  <meta name="twitter:image" content="https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=1200&h=630&fit=crop">

  <link rel="icon" type="image/svg+xml" href="../favicon.svg">

  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Article",
    "headline": "The Red Line: Anthropic Said No to Mass Surveillance. OpenAI Said Yes to the Pentagon.",
    "description": "Anthropic refused to let the US military use Claude without ethical safeguards. The government threatened retaliation. Then OpenAI swooped in with a deal. Here's what happened and why it matters.",
    "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=1200&h=630&fit=crop",
    "datePublished": "2026-02-28",
    "dateModified": "2026-02-28",
    "author": {
      "@type": "Person",
      "name": "Sami",
      "url": "https://chsami.com/about.html"
    },
    "publisher": {
      "@type": "Organization",
      "name": "CHSAMI",
      "url": "https://chsami.com",
      "logo": {
        "@type": "ImageObject",
        "url": "https://chsami.com/og-image.png"
      }
    },
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://chsami.com/posts/anthropic-vs-openai-surveillance.html"
    }
  }
  </script>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://api.fontshare.com/v2/css?f[]=satoshi@400,500,700,900&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;700&display=swap" rel="stylesheet">
  <style>
    *, *::before, *::after {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }

    :root {
      --bg-primary: #F8F6F1;
      --bg-card: #FFFFFF;
      --text-primary: #1A1A1A;
      --text-secondary: #6B6B6B;
      --text-muted: #888888;
      --text-light: #A8A4A0;
      --border-color: #E8E4DC;
      --accent: #1A1A1A;
    }

    body {
      min-height: 100vh;
      background-color: var(--bg-primary);
      font-family: 'Satoshi', 'Helvetica Neue', sans-serif;
      color: var(--text-primary);
      line-height: 1.6;
    }

    .header {
      padding: 48px 60px 32px;
      border-bottom: 1px solid var(--border-color);
    }

    .back-link {
      font-family: 'JetBrains Mono', monospace;
      font-size: 11px;
      letter-spacing: 0.1em;
      text-transform: uppercase;
      color: var(--text-muted);
      text-decoration: none;
      display: inline-flex;
      align-items: center;
      gap: 8px;
      transition: color 0.2s ease;
    }

    .back-link:hover { color: var(--text-primary); }

    .hero {
      padding: 80px 60px;
      max-width: 1400px;
      margin: 0 auto;
    }

    .hero-label {
      font-family: 'JetBrains Mono', monospace;
      font-size: 10px;
      letter-spacing: 0.2em;
      text-transform: uppercase;
      color: var(--text-muted);
      margin-bottom: 24px;
    }

    .hero-title {
      font-size: 64px;
      font-weight: 900;
      letter-spacing: -0.04em;
      line-height: 1.05;
      margin-bottom: 16px;
    }

    .hero-title span {
      display: block;
      font-weight: 400;
      font-size: 26px;
      letter-spacing: 0.02em;
      color: var(--text-secondary);
      margin-top: 12px;
    }

    .hero-desc {
      font-size: 19px;
      line-height: 1.7;
      color: var(--text-secondary);
      max-width: 760px;
      margin-top: 32px;
    }

    .content {
      max-width: 1400px;
      margin: 0 auto;
      padding: 0 60px 80px;
    }

    .section-header {
      display: flex;
      align-items: baseline;
      gap: 24px;
      margin-bottom: 40px;
      padding-top: 64px;
      border-top: 1px solid var(--border-color);
    }

    .section-number {
      font-family: 'JetBrains Mono', monospace;
      font-size: 96px;
      font-weight: 500;
      color: var(--border-color);
      line-height: 1;
    }

    .section-title {
      font-size: 36px;
      font-weight: 700;
      letter-spacing: -0.02em;
    }

    .section-subtitle {
      font-family: 'JetBrains Mono', monospace;
      font-size: 12px;
      letter-spacing: 0.1em;
      text-transform: uppercase;
      color: var(--text-muted);
      margin-top: 8px;
    }

    .grid-2 {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      gap: 32px;
    }

    .grid-3 {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 24px;
    }

    .card {
      background: var(--bg-card);
      padding: 36px;
      position: relative;
    }

    .card::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      width: 4px;
      height: 100%;
      background: var(--text-primary);
    }

    .card-title {
      font-size: 22px;
      font-weight: 700;
      letter-spacing: -0.02em;
      margin-bottom: 12px;
    }

    .card-desc {
      font-size: 15px;
      color: var(--text-secondary);
      line-height: 1.7;
    }

    .meta {
      font-family: 'JetBrains Mono', monospace;
      font-size: 11px;
      letter-spacing: 0.08em;
      text-transform: uppercase;
      color: var(--text-muted);
    }

    .list {
      display: grid;
      gap: 16px;
      margin-top: 16px;
    }

    .list-item {
      display: grid;
      grid-template-columns: 80px 1fr;
      gap: 16px;
      align-items: start;
    }

    .list-label {
      font-family: 'JetBrains Mono', monospace;
      font-size: 12px;
      letter-spacing: 0.12em;
      text-transform: uppercase;
      color: var(--text-muted);
    }

    .list-body {
      font-size: 15px;
      color: var(--text-secondary);
      line-height: 1.7;
    }

    .highlight-box {
      background: var(--text-primary);
      color: var(--bg-primary);
      padding: 40px;
      margin-top: 32px;
    }

    .highlight-box .card-title {
      color: var(--bg-primary);
    }

    .highlight-box .card-desc {
      color: rgba(248, 246, 241, 0.8);
    }

    .quote-block {
      border-left: 4px solid var(--text-primary);
      padding: 24px 32px;
      margin-top: 24px;
      background: var(--bg-card);
    }

    .quote-text {
      font-size: 17px;
      line-height: 1.7;
      color: var(--text-secondary);
      font-style: italic;
    }

    .quote-attr {
      font-family: 'JetBrains Mono', monospace;
      font-size: 11px;
      letter-spacing: 0.08em;
      text-transform: uppercase;
      color: var(--text-muted);
      margin-top: 12px;
    }

    .comparison-table {
      width: 100%;
      margin-top: 32px;
      border-collapse: collapse;
    }

    .comparison-table th {
      font-family: 'JetBrains Mono', monospace;
      font-size: 11px;
      letter-spacing: 0.1em;
      text-transform: uppercase;
      color: var(--text-muted);
      padding: 16px 24px;
      text-align: left;
      border-bottom: 2px solid var(--text-primary);
    }

    .comparison-table td {
      font-size: 15px;
      color: var(--text-secondary);
      line-height: 1.6;
      padding: 16px 24px;
      border-bottom: 1px solid var(--border-color);
      vertical-align: top;
    }

    .comparison-table tr:last-child td {
      border-bottom: none;
    }

    .comparison-table td:first-child {
      font-family: 'JetBrains Mono', monospace;
      font-size: 12px;
      letter-spacing: 0.08em;
      text-transform: uppercase;
      color: var(--text-muted);
      white-space: nowrap;
      width: 160px;
    }

    .cta {
      background: var(--text-primary);
      color: var(--bg-primary);
      padding: 56px;
      margin-top: 64px;
      text-align: center;
    }

    .cta-label {
      font-family: 'JetBrains Mono', monospace;
      font-size: 10px;
      letter-spacing: 0.15em;
      text-transform: uppercase;
      opacity: 0.6;
      margin-bottom: 12px;
    }

    .cta-title {
      font-size: 30px;
      font-weight: 700;
      letter-spacing: -0.02em;
      margin-bottom: 12px;
    }

    .cta-desc {
      font-size: 16px;
      opacity: 0.85;
      line-height: 1.7;
      max-width: 640px;
      margin: 0 auto;
    }

    .footer {
      border-top: 1px solid var(--border-color);
      padding: 40px 60px;
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    .footer-text {
      font-family: 'JetBrains Mono', monospace;
      font-size: 11px;
      color: var(--text-muted);
    }

    .footer-link {
      font-family: 'JetBrains Mono', monospace;
      font-size: 11px;
      color: var(--text-primary);
      text-decoration: none;
      letter-spacing: 0.05em;
    }

    .footer-link:hover { text-decoration: underline; }

    @media (max-width: 1100px) {
      .grid-2 { grid-template-columns: 1fr; }
      .grid-3 { grid-template-columns: repeat(2, 1fr); }
      .comparison-table { font-size: 14px; }
    }

    @media (max-width: 768px) {
      .hero { padding: 56px 24px; }
      .hero-title { font-size: 42px; }
      .hero-title span { font-size: 18px; }
      .hero-desc { font-size: 17px; }
      .content { padding: 0 24px 56px; }
      .section-header { flex-direction: column; gap: 12px; padding-top: 48px; }
      .section-number { font-size: 56px; }
      .section-title { font-size: 26px; }
      .grid-3 { grid-template-columns: 1fr; }
      .card { padding: 28px; }
      .list-item { grid-template-columns: 1fr; }
      .comparison-table th,
      .comparison-table td { padding: 12px 16px; }
      .comparison-table td:first-child { white-space: normal; }
      .footer { flex-direction: column; gap: 16px; text-align: center; }
    }

    @media (max-width: 480px) {
      .hero { padding: 40px 20px; }
      .hero-title { font-size: 32px; }
      .hero-desc { font-size: 15px; }
      .content { padding: 0 20px 40px; }
      .card-title { font-size: 18px; }
      .card-desc { font-size: 14px; }
    }
  </style>
</head>
<body>
  <header class="header">
    <a class="back-link" href="../index.html">&larr; Back to Home</a>
  </header>

  <main>
    <section class="hero">
      <div class="hero-label">AI &amp; Policy &middot; February 2026</div>
      <h1 class="hero-title">The Red Line<span>Anthropic said no to mass surveillance. Then OpenAI called the Pentagon.</span></h1>
      <p class="hero-desc">
        In February 2026, Anthropic refused to let the US military use Claude without ethical safeguards. Defense Secretary Pete Hegseth gave CEO Dario Amodei a Friday deadline to comply or face retaliation. Anthropic did not budge. Two red lines stayed in place: no autonomous weapons, no domestic mass surveillance. Days later, President Trump banned Anthropic from government systems and designated it a supply-chain risk. Hours after that, Sam Altman posted a tweet announcing OpenAI had signed a deal with the Department of War. Same red lines on paper. Very different companies behind them.
      </p>
    </section>

    <section class="content">
      <div class="section-header">
        <div class="section-number">01</div>
        <div>
          <div class="section-title">What Anthropic refused to do</div>
          <div class="section-subtitle">Two lines they would not cross</div>
        </div>
      </div>
      <div class="grid-2">
        <div class="card">
          <div class="card-title">The ultimatum</div>
          <p class="card-desc">
            Anthropic was the first AI company approved to operate on the Pentagon's classified military networks, working alongside partners like Palantir. Last summer, the Pentagon awarded defense contracts worth up to $200 million each to four AI companies: Anthropic, Google, OpenAI, and Elon Musk's xAI. But Anthropic's contract came with conditions. CEO Dario Amodei had drawn two hard lines: Claude would not be used for fully autonomous targeting operations, and it would not be used for domestic mass surveillance of American citizens. In late February, Defense Secretary Pete Hegseth sat across from Amodei and gave him a Friday deadline. Remove the restrictions or lose the contract. The Pentagon's position was blunt: military operations need tools without built-in limitations, and lawful use is the military's responsibility, not the vendor's.
          </p>
        </div>
        <div class="card">
          <div class="card-title">Why Anthropic held firm</div>
          <p class="card-desc">
            Amodei did not budge. In an essay published in January 2026, he laid out why mass surveillance represented a unique danger: "A powerful AI looking across billions of conversations from millions of people could gauge public sentiment, detect pockets of disloyalty forming, and stamp them out before they grow." This was not a hypothetical. Anthropic's argument was that the government's definition of "lawful" is self-certifying. The government decides what is lawful, then certifies its own compliance. Anthropic said mass surveillance should be prohibited per se, regardless of whether the government labels it lawful. The distinction is critical: OpenAI's later agreement prohibits "unlawful" surveillance as determined by the government. Anthropic's policy prohibited mass surveillance outright, even if the government certified it as legal.
          </p>
        </div>
      </div>

      <div class="quote-block">
        <p class="quote-text">"We are considerably closer to real danger in 2026 than we were in 2023. These risks should be managed in a realistic, pragmatic manner."</p>
        <div class="quote-attr">Dario Amodei &mdash; CEO, Anthropic &mdash; January 2026</div>
      </div>

      <div class="section-header">
        <div class="section-number">02</div>
        <div>
          <div class="section-title">The government's retaliation</div>
          <div class="section-subtitle">Escalation in five days</div>
        </div>
      </div>
      <div class="card">
        <div class="card-title">A timeline of pressure</div>
        <div class="list">
          <div class="list-item">
            <div class="list-label">Feb 24</div>
            <div class="list-body">US military leaders meet with Anthropic to argue against Claude's safeguards. Hegseth gives Amodei a Friday deadline: open the technology for unrestricted use or risk losing the government contract. The tone is described as cordial, but the threats are not.</div>
          </div>
          <div class="list-item">
            <div class="list-label">Feb 25</div>
            <div class="list-body">Pentagon officials warn they could designate Anthropic a supply-chain risk or invoke the Defense Production Act, which would give the military authority to use Anthropic's products regardless of the company's approval. Hegseth publicly states he is shrugging off any AI models "that won't allow you to fight wars."</div>
          </div>
          <div class="list-item">
            <div class="list-label">Feb 26</div>
            <div class="list-body">Google workers begin circulating an internal petition seeking "red lines" on military AI, echoing Anthropic's stance. The debate spills beyond a single company.</div>
          </div>
          <div class="list-item">
            <div class="list-label">Feb 27</div>
            <div class="list-body">Hegseth directs the Department of War to designate Anthropic a supply-chain risk. President Trump bans Anthropic from use in government systems. Dario Amodei publishes a formal statement reaffirming Anthropic's position on safeguards. The Hacker News thread on the ban draws over 870 comments. The statement thread gets over 1,500.</div>
          </div>
          <div class="list-item">
            <div class="list-label">Feb 28</div>
            <div class="list-body">Sam Altman posts a tweet announcing OpenAI has reached an agreement with the Department of War to deploy models in their classified network. Hours earlier, current and former employees of Google and OpenAI launch notdivided.org, a signed open letter opposing the government's actions.</div>
          </div>
        </div>
      </div>

      <div class="section-header">
        <div class="section-number">03</div>
        <div>
          <div class="section-title">Why Anthropic does not want mass surveillance</div>
          <div class="section-subtitle">Three reasons, not just one</div>
        </div>
      </div>
      <div class="grid-3">
        <div class="card">
          <div class="meta">Ethical</div>
          <div class="card-title">The founding principle</div>
          <p class="card-desc">
            Anthropic was founded in 2021 by former OpenAI researchers who left specifically over concerns about AI safety. Dario and Daniela Amodei built the company around the premise that AI development must come with hard constraints. For Anthropic, mass surveillance is not a gray area or a policy to be negotiated. It is a categorical line. An AI that can scan billions of conversations to identify dissent before it organizes is, in their view, a tool that no government should possess regardless of intent. The argument is that capability creates temptation, and once the infrastructure exists, the safeguards around it inevitably erode.
          </p>
        </div>
        <div class="card">
          <div class="meta">Strategic</div>
          <div class="card-title">The business case</div>
          <p class="card-desc">
            Claude's primary customer base is millions of developers and enterprises who are overwhelmingly opposed to government surveillance. One Hacker News commenter put it bluntly: giving up ethical credibility so that Hegseth "can do a few more war crimes before he gets fired in 2027 after the midterms" is not worth the enormous hit to Anthropic's reputation across its core market. The $200 million Pentagon contract, while significant, is dwarfed by the commercial revenue that depends on trust. Developers choose tools they believe in. Anthropic's brand as the "safety-first" AI company is not just marketing. It is the business model.
          </p>
        </div>
        <div class="card">
          <div class="meta">Technical</div>
          <div class="card-title">The precedent problem</div>
          <p class="card-desc">
            If Anthropic allows exceptions for one government's definition of "lawful use," it sets a precedent for every government. China, Russia, Saudi Arabia, any state with purchasing power could make the same argument: our surveillance is lawful under our laws, so your AI must comply. A bright-line rule that mass surveillance is prohibited regardless of jurisdiction gives Anthropic a defensible position globally. A flexible rule that defers to each government's self-certification makes it impossible to refuse anyone. Anthropic chose the only position that scales without collapsing into complicity.
          </p>
        </div>
      </div>

      <div class="section-header">
        <div class="section-number">04</div>
        <div>
          <div class="section-title">OpenAI's deal with the Department of War</div>
          <div class="section-subtitle">Sam Altman's tweet and the reaction</div>
        </div>
      </div>
      <div class="grid-2">
        <div class="card">
          <div class="card-title">The announcement</div>
          <p class="card-desc">
            On February 28, Sam Altman posted on X: "Tonight, we reached an agreement with the Department of War to deploy our models in their classified network." The tweet came hours after the government banned Anthropic and designated it a supply-chain risk. OpenAI's statement included language about prohibiting domestic mass surveillance and requiring human responsibility for the use of force, including autonomous weapon systems. On paper, these were the same principles Anthropic had demanded. The Department of War, which had just punished Anthropic for insisting on exactly these safeguards, agreed to them with OpenAI. The timing was not lost on anyone.
          </p>
        </div>
        <div class="card">
          <div class="card-title">The backlash</div>
          <p class="card-desc">
            The reaction on Hacker News, Reddit, and X was immediate and overwhelmingly skeptical. "So they agreed to the exact same clauses that Anthropic put forward but with OpenAI instead?" one commenter wrote. "So it wasn't about those principles making them a supply chain risk? They're just trying to punish Anthropic for being the first ones to stand firm?" Others pointed out a critical difference: OpenAI's agreement prohibits "unlawful" surveillance as determined by the government itself, while Anthropic prohibited mass surveillance categorically. Multiple commenters speculated that Altman had leveraged political connections to undermine Anthropic. "Sam saw Anthropic was getting too competitive. So he called his buddies in the gov to knock them down a peg."
          </p>
        </div>
      </div>

      <div class="highlight-box">
        <div class="card-title">"We Will Not Be Divided"</div>
        <p class="card-desc">
          On the same day as Altman's announcement, current and former employees of Google and OpenAI launched notdivided.org, a signed open letter opposing the government's actions against Anthropic. Signatures are verified through company email addresses. Anonymous signing is supported, with personal data automatically deleted within 24 hours of verification. The letter's premise is that AI companies should not be bullied into enabling surveillance, and that the workers building these systems have a stake in how they are used. It is the first organized cross-company employee response in the AI industry to a government coercion campaign.
        </p>
      </div>

      <div class="section-header">
        <div class="section-number">05</div>
        <div>
          <div class="section-title">OpenAI vs Anthropic</div>
          <div class="section-subtitle">Two companies, two philosophies</div>
        </div>
      </div>

      <table class="comparison-table">
        <thead>
          <tr>
            <th></th>
            <th>Anthropic</th>
            <th>OpenAI</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Founded</td>
            <td>2021, by former OpenAI researchers who left over safety concerns</td>
            <td>2015, as a nonprofit AI research lab. Converted to capped-profit in 2019, pursuing full for-profit conversion</td>
          </tr>
          <tr>
            <td>Leadership</td>
            <td>Dario Amodei (CEO) and Daniela Amodei (President). Research-driven leadership with published positions on AI risk</td>
            <td>Sam Altman (CEO). Business-driven leadership with close ties to Washington and Silicon Valley investors</td>
          </tr>
          <tr>
            <td>Safety approach</td>
            <td>Hard constraints: categorical red lines that cannot be overridden by customer demand or government pressure</td>
            <td>Flexible guardrails: safety principles that can be adjusted per agreement, with enforcement deferred to the customer</td>
          </tr>
          <tr>
            <td>Surveillance stance</td>
            <td>Mass surveillance prohibited outright, even if a government certifies it as lawful</td>
            <td>Prohibits "unlawful" surveillance, as defined by the government itself</td>
          </tr>
          <tr>
            <td>Military position</td>
            <td>First AI company on Pentagon classified networks. Refused to remove safeguards. Banned from government systems</td>
            <td>Joined Pentagon's unclassified GenAI.mil network in early February. Signed classified network deal on February 28</td>
          </tr>
          <tr>
            <td>Government relationship</td>
            <td>Aligned with Biden administration on AI oversight. At odds with Trump administration. Hired ex-Biden officials but also added a former Trump White House official to its board</td>
            <td>Pragmatic alignment with current administration. OpenAI co-founder donated $25 million to Trump's 2024 campaign</td>
          </tr>
          <tr>
            <td>Corporate structure</td>
            <td>Public benefit corporation. Mission-oriented charter with safety as a stated priority above profit</td>
            <td>Transitioning from capped-profit to full for-profit. Originally a nonprofit, now structured around investor returns</td>
          </tr>
          <tr>
            <td>Trust model</td>
            <td>"We will constrain our own product even at the cost of revenue." Credibility built on actions that cost money</td>
            <td>"We will work within whatever framework the customer requires." Credibility built on scale and market position</td>
          </tr>
        </tbody>
      </table>

      <div class="cta">
        <div class="cta-label">The bottom line</div>
        <div class="cta-title">The difference is not in the words. It is in who decides what they mean.</div>
        <p class="cta-desc">
          Both companies now claim to oppose mass surveillance. The difference is that Anthropic's policy is self-enforcing: mass surveillance is prohibited, full stop. OpenAI's policy defers enforcement to the very institution using the technology. When the government gets to define what counts as "lawful," the safeguard exists only as long as the government wants it to. That is not a red line. It is a suggestion.
        </p>
      </div>
    </section>
  </main>

  <footer class="footer">
    <div class="footer-text">Published 2026&middot;02&middot;28 &middot; 10 min read</div>
    <a class="footer-link" href="../index.html">Back to Home &rarr;</a>
  </footer>
</body>
</html>
